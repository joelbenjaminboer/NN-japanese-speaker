DATA_URL: "https://archive.ics.uci.edu/ml/machine-learning-databases/JapaneseVowels/"

SEED: 42
MAX_LEN: 29  # longest utterance length (7â€“29)
N_FEATURES: 12

AUGMENTATION:
  AUGMENT: false
  REPEATS: 2
  AUG_FILE: "data/augmented_data.npz"
  SEED: 42
  STEPS:
    - type: gaussian_noise
      noise_factor: 0.001
      p: 1.0
    - type: random_scaling
      scale_range: [0.95, 1.05]
    - type: time_masking
      max_mask_percentage: 0.01
    # - type: frequency_masking
    #   max_mask_percentage: 0.01

EMBEDDING:
  MODEL: "nomic-ai/nomic-embed-text-v1.5"
  DIMENSION: 512
  PRE_PRECISION: 2
  BATCH_SIZE: 256  # Batch size for embedding (higher = faster, but uses more GPU memory)
  OUTPUT_FILE: "data/processed_data/"
  KEY: "augment512"

INPUT_DIRS:
  TRAIN_FILE: "data/ae.train"
  TEST_FILE: "data/ae.test"

OUTPUT_DIRS:
  PROCESSED: "data/processed_data"
  FIGURES: "reports/figures_v3"
  MODELS: "models_v3"

#HAIKU
MODEL:
  LOAD_BEST_CONFIG: false
  NUM_CLASSES: 9
  EMBEDDING_DIM: 512
  KERNEL_SIZE: 3
  CONV_CHANNELS: 128
  DROPOUT: 0.3
  INPUT_CHANNELS: 12
  HIDDEN_DIM: 64
  LEARNING_RATE: 0.001  # Conservative starting point for large batches
  BATCH_SIZE: 4096  # H100-optimized: 80GB memory allows huge batches
  NUM_EPOCHS: 500  # Reduced: large batches converge faster
  K_FOLDS: 5
  NUM_WORKERS: 0  # Set to 0 for GPU training (data already on GPU)
  PIN_MEMORY: false  # Not needed when data is on GPU
  DEVICE: "cuda"

OPTUNA:
  ENABLED: true  # Enable for augmentation experiment
  SHOW_PROGRESS_BAR: true
  N_TRIALS: 100  # More trials for joint optimization (augmentation + model)
  STUDY_NAME: "augmentation_optimization_v3"
  STORAGE_URL: "sqlite:///exp_augmentation_study_v3.db"
  FIGURES_DIR: "reports/optuna/figures_v3"
  STUDY_DIR: "reports/optuna/studys_v3"
  BEST_CONFIG_DIR: "reports/optuna/best_config_v3"
  RANGES:
    LEARNING_RATE: [1e-5, 1e-2] # low, high
    DROPOUT: [0.1, 0.5] # low, high
    CONV_CHANNELS: [128, 256, 512]
    HIDDEN_DIM: [16, 32, 64, 128]
    KERNEL_SIZE: [3, 5, 7, 9]
    BATCH_SIZE: [2048, 4096, 8192]  # H100-optimized: leverage massive memory & compute
